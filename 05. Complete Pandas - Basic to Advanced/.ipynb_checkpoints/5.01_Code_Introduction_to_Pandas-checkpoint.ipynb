{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e4e0797f-a976-4229-8fcf-7a279b399ca9",
      "metadata": {
        "id": "e4e0797f-a976-4229-8fcf-7a279b399ca9"
      },
      "source": [
        "# Pandas-1: Introduction to Pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motivation\n",
        "\n",
        "- Must-have for **AI/ML coding rounds** in startups as well as Product based Companies.\n",
        "- **Easy to Use toolkit** for both beginners and pro developers.\n",
        "- pandas lets you quickly load, clean, analyze, and visualize data like a pro.\n",
        "- Whenever data is **Tabular or 2-Dimensional,** always think of Pandas.\n",
        "- Knowing pandas is a sought-after skill for roles in **data science, business analysis, research, and beyond**. It makes your resume stand out.\n",
        "- Essential for working on **machine learning**, **data science**, and **deep learning** projects  \n"
      ],
      "metadata": {
        "id": "KSe1Z_K47tb_"
      },
      "id": "KSe1Z_K47tb_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## What is Pandas?\n",
        "**pandas** is an **open-source Python library** for **data manipulation and analysis**.  \n",
        "It is built on top of **NumPy** and provides powerful tools to work with structured data like tables (rows and columns).\n",
        "\n",
        "Think of pandas as **Excel for Python** — but faster, more flexible, and much more powerful.\n",
        "\n"
      ],
      "metadata": {
        "id": "__y611QJ4Xdq"
      },
      "id": "__y611QJ4Xdq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Why Pandas?\n",
        "Without pandas, you’d need to manually manage Tabular data for data operations — which gets messy and slow.  \n",
        "Pandas:\n",
        "- Handles large datasets efficiently.\n",
        "- Provides easy syntax for **filtering, grouping, joining, reshaping** data.\n",
        "- Integrates well with **NumPy**, **Matplotlib**, and other data-science libraries.\n",
        "\n"
      ],
      "metadata": {
        "id": "3q6W5fMC4eYJ"
      },
      "id": "3q6W5fMC4eYJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Core Data Structures\n",
        "Pandas provides two main data structures:\n",
        "\n",
        "1. **Series**  \n",
        "   - 1D labeled array (like one column in a spreadsheet)  \n",
        "   - Labels are called **index**  \n",
        "   ```python\n",
        "   import pandas as pd\n",
        "   s = pd.Series([10, 20, 30], index=[\"a\", \"b\", \"c\"])\n",
        "   print(s)\n"
      ],
      "metadata": {
        "id": "Rm3txwOg4kDX"
      },
      "id": "Rm3txwOg4kDX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **DataFrame**  \n",
        "   - 2D table with rows and columns  \n",
        "   - Each column is a `Series`  \n",
        "   ```python\n",
        "   data = {\n",
        "       \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "       \"Age\": [25, 30, 35]\n",
        "   }\n",
        "   df = pd.DataFrame(data)\n",
        "   print(df)\n"
      ],
      "metadata": {
        "id": "2wB5oH2J44Ex"
      },
      "id": "2wB5oH2J44Ex"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Key Features\n",
        "- **Data cleaning** → Handle missing values (`fillna`, `dropna`)\n",
        "- **Data selection & filtering** → Use labels (`loc`) or positions (`iloc`)\n",
        "- **Aggregation & grouping** → `groupby`, `sum`, `mean`\n",
        "- **Merging & joining** → Combine multiple datasets (`merge`, `concat`)\n",
        "- **Reshaping** → Pivot tables, stack/unstack\n",
        "- **I/O operations** → Read/write CSV, Excel, SQL, JSON, etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "LtzOag8046TY"
      },
      "id": "LtzOag8046TY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Example\n"
      ],
      "metadata": {
        "id": "-AXYv1Zl5J4H"
      },
      "id": "-AXYv1Zl5J4H"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "\n",
        "# The Iris dataset has no header, so specify column names\n",
        "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
        "\n",
        "# Read CSV without index column\n",
        "df = pd.read_csv(url, header=None, names=column_names, index_col=False)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsZMKCBX4t1G",
        "outputId": "e48bf40b-d586-429f-d35b-16cd2e47fc95"
      },
      "id": "nsZMKCBX4t1G",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width        class\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnC0Sgh15cI1",
        "outputId": "c3cc85ff-bd07-4a78-c8e5-8f52a86bab07"
      },
      "id": "NnC0Sgh15cI1",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   class         150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4aa81f8-210d-44b2-8ca8-fdfd08e373cd",
      "metadata": {
        "id": "e4aa81f8-210d-44b2-8ca8-fdfd08e373cd"
      },
      "source": [
        "---\n",
        "## Pandas vs NumPy - Which one to use and When?\n",
        "\n",
        "- Dimension > 2: Use NumPy\n",
        "- Use NumPy (ndarray) when your 2-D data is essentially a numeric matrix and you need fast, memory-efficient numerical work (linear algebra, broadcasting, heavy elementwise operations).\n",
        "- Use pandas (DataFrame) when your 2-D data is a table — i.e., columns with names, mixed dtypes, missing values, need for grouping/joins/time-series/CSV/Excel IO or easy selection by column name.\n",
        "\n",
        "---\n",
        "## Practical rule of Thumb\n",
        "\n",
        "Start with pandas for data cleaning and exploration. When doing heavy numeric computations (matrix factorization, linear algebra), convert the numeric columns to a NumPy array."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Will Pandas work when data is larger than memory ?\n",
        "\n",
        "Since Pandas loads the entire dataset into memory. if data is larger than the main memory Here are practical approaches:\n",
        "\n",
        "1. **Dask :** A library that extends pandas with parallel computing and chunked processing.\n",
        "2. **Polars :** A fast DataFrame library written in Rust, with lazy execution and streaming.\n",
        "3. \"PySpark :\" A distributed big-data engine. PySpark splits the dataset into chunks (partitions) and processes them sequentially or in parallel — only a small chunk is in memory at a time.\n",
        "---"
      ],
      "metadata": {
        "id": "K9vYJdnmTS2s"
      },
      "id": "K9vYJdnmTS2s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Happy Learning ! Team DecodeAiML !!"
      ],
      "metadata": {
        "id": "ouYT-gTHVCe6"
      },
      "id": "ouYT-gTHVCe6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}